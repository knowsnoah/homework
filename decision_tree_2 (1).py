# -*- coding: utf-8 -*-
"""decision_tree_2

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1a5vj0RXJIXfgSflyT9-uS_t6e3Q4_Or8
"""

#-------------------------------------------------------------------------
# AUTHOR: Noah Ojeda
# FILENAME: decision_tree_2.py
# SPECIFICATION: This program trains and evaluates a decision tree classifier
# using three different training datasets about contact lens prescriptions.
# It converts categorical features into numerical form, trains the model using
# entropy as the impurity measure, and tests its performance on a separate
# test dataset. The program runs the training/testing process multiple times
# to compute an average accuracy and visualizes the final decision tree.
# FOR: CS 4210 - Assignment #2
# TIME SPENT: ~1.5hr
#-------------------------------------------------------------------------

# IMPORTANT NOTE: YOU ARE ALLOWED TO USE ANY PYTHON LIBRARY TO COMPLETE THIS PROGRAM

# Importing some Python libraries
from sklearn import tree
import pandas as pd
import matplotlib.pyplot as plt

dataSets = [
    'contact_lens_training_1.csv',
    'contact_lens_training_2.csv',
    'contact_lens_training_3.csv'
]

# Reading the test data in a csv file using pandas
dbTest = []
df_test = pd.read_csv('contact_lens_test.csv')
for _, row in df_test.iterrows():
    dbTest.append(row.tolist())

#Features mappings
feature_map = {
    "Age": {'Young': 0, 'Presbyopic': 1, 'Prepresbyopic': 2},
    "Spectacle Prescription": {'Myope': 0, 'Hypermetrope': 1},
    "Astigmatism": {'No': 0, 'Yes': 1},
    "Tear Production Rate": {'Reduced': 0, 'Normal': 1}
}

#Class mapping
class_map = {'Yes': 2, 'No': 1}

#Beginning of the loop
for ds in dataSets:
    dbTraining = []
    X = []
    Y = []

    # Reading the training data in a csv file using pandas
    # --> add your Python code here
    dbTraining = pd.read_csv(ds)

    # Transform the original categorical training features to numbers and add to X.
    # Example: Young = 1, Prepresbyopic = 2, Presbyopic = 3
    # X = [[1, 1, 1, 1], [2, 2, 2, 2], ...]
    # --> add your Python code here
    # Transform the original categorical training classes to numbers and add to Y.
    # Example: Yes = 1 and No = 2, Y = [1, 1, 2, 2, ...]
    # --> add your Python code here
    for _, row in dbTraining.iterrows():
        X.append([
            feature_map["Age"][row["Age"]],
            feature_map["Spectacle Prescription"][row["Spectacle Prescription"]],
            feature_map["Astigmatism"][row["Astigmatism"]],
            feature_map["Tear Production Rate"][row["Tear Production Rate"]]
        ])
        Y.append(class_map[row["Recommended Lenses"]])

    # Loop your training and test tasks 10 times here
    sum_accuracy = 0.0
    for i in range(10):
        # Fitting the decision tree to the data using entropy as your impurity measure
        # and maximum depth = 5
        # --> add your Python code here
        clf = tree.DecisionTreeClassifier(criterion='entropy', max_depth=5)
        clf.fit(X, Y)

        # Read the test data and add this data to dbTest
        # --> add your Python code here
        numberCorrect = 0
        total = len(dbTest)

        for data in dbTest:
            # Transform the features of the test instances to numbers
            # (same strategy as during training).
            # Example:
            # class_predicted = clf.predict([[3, 1, 2, 1]])[0]
            # --> add your Python code here
            x_test = [
                feature_map["Age"][data[0]],
                feature_map["Spectacle Prescription"][data[1]],
                feature_map["Astigmatism"][data[2]],
                feature_map["Tear Production Rate"][data[3]]
            ]

            y_test = clf.predict([x_test])[0]

            # Compare the prediction with the true label (located at data[4]) of the test instance
            # to start calculating accuracy.
            # --> add your Python code here
            if y_test == class_map[data[4]]:
                numberCorrect += 1

        # Find the average of this model during the 10 runs (training and test set)
        # --> add your Python code here
        run_accuracy = numberCorrect / total
        sum_accuracy += run_accuracy

    # Print the average accuracy of this model during the 10 runs (training and test set).
    # Example: "final accuracy when training on contact_lens_training_1.csv: 0.2"
    # --> add your Python code here
    avg_accuracy = sum_accuracy / 10.0
    print(f"final accuracy when training on {ds}: {avg_accuracy:.5f}")

#plotting the decision tree
tree.plot_tree(clf, feature_names=['Age', 'Spectacle', 'Astigmatism', 'Tear'],
  class_names=['Yes','No'], filled=True, rounded=True)
plt.show()



