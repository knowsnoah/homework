# -*- coding: utf-8 -*-
"""decision_tree

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ZdfmvIla7MlYJCfKFJ33WQxitpBIZA34
"""

#-------------------------------------------------------------------------
# AUTHOR: Noah Ojeda
# FILENAME: decision_tree.py
# SPECIFICATION: This program createts a decision tree based off the file "contact_lens.csv" to determine
# whether or not an instance is recommended contact lenese by using the attributes and features from the
# 10 instances.
# FOR: CS 4210- Assignment #1
# TIME SPENT: ~1hr
#-----------------------------------------------------------*/
#IMPORTANT NOTE: DO NOT USE ANY ADVANCED PYTHON LIBRARY TO COMPLETE THIS CODE SUCH
# AS numpy OR pandas. You have to work here only with standard
# dictionaries, lists, and arrays
#importing some Python libraries
from sklearn import tree
import matplotlib.pyplot as plt
import csv
db = []
X = []
Y = []
#reading the data in a csv file
with open('contact_lens.csv', 'r') as csvfile:
  reader = csv.reader(csvfile)
  for i, row in enumerate(reader):
      if i > 0: #skipping the header
        db.append (row)


feature_map = {
    "Age" : {'Young': 0, 'Presbyopic' : 1, 'Prepresbyopic': 2},
    "Spectacle Prescription" : {'Myope' : 0, 'Hypermetrope' : 1},
    "Astigmatism" : {'No' : 0, 'Yes' : 1},
    "Tear Production Rate" : {'Reduced' : 0, 'Normal' : 1}
}

class_map = {"No": 0, "Yes": 1}

#encode the original categorical training features into numbers and add to the array X.
#--> add your Python code here
# X =
#encode the original categorical training classes into numbers and add to the vector Y.
#--> addd your Python code here
# Y =
for row in db:
    age, spectacle, astigmatism, tear, result = row[0], row[1], row[2], row[3], row[4]
    X.append([
        feature_map["Age"][age],
        feature_map["Spectacle Prescription"][spectacle],
        feature_map["Astigmatism"][astigmatism],
        feature_map["Tear Production Rate"][tear]
    ])
    Y.append(class_map[result])

print(X)
print()
print(Y)

#fitting the decision tree to the data using entropy as your impurity measure
#--> addd your Python code here
clf = tree.DecisionTreeClassifier(criterion = 'entropy')
clf = clf.fit(X, Y)

#plotting the decision tree
tree.plot_tree(clf, feature_names=['Age', 'Spectacle', 'Astigmatism', 'Tear'],
  class_names=['Yes','No'], filled=True, rounded=True)
plt.show()